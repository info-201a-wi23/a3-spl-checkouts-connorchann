---
title: "A3: SPL Library Checkouts in relation to the novel, Normal People"
author: "Connor Chan"
output: html_document
---


### Introduction

For Assignment 3, I am examining data from the Seattle Public Library, more specifically checkout data from the novel, Normal People, written by Sally Rooney. The dataset I chose from the public library includes both univariate and multivariate categories including Usage Class, Checkout Type, Material Type, Checkout Year, Checkout Month, number of checkouts, Title, ISBN, author, genre, Publisher, and Publication Year.

I am choosing to examine this dataset because I am currently reading Normal People, and I am interested in learning about the popularity of the novel between its publish date and today.

### Summary Information

```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = FALSE, message = FALSE)

# read the CSV file into a variable called "normal_data"
normal_data <- read.csv("file:///Users/connorchan/Library/Messages/Attachments/dd/13/00961DEA-54E7-47C6-84E3-697CD2A044EA/Normal_People_A3_Checkouts_by_Title.csv")

library("dplyr")
library("stringr")
library("ggplot2")
library("scales")
library(tidyverse)

```

For research questions, I drew questions from the inspiration section of the dataset as well as from my personal interests. All of my questions are related to the dataset chosen regarding the novel, Normal People.

When observing the dataset for the first time, I analyzed the variables and values associated with the checkout data from the Seattle Public Library. In this time frame, I became curious about the checkout data metrics. And so, I calculated and determined the average number of checkouts, which totals `avg_num_of_checkouts.R`. Looking closer at the variables listed in the dataset, I began to question checkout months, specifically which month had the most checkouts. I soon discovered `month_with_most_checkouts.R` after totaling all checkouts by month. Similarly, I calculated the least amount of checkouts per year being `year_with_least_checkouts.R`. After using checkout data to find values including mean, max, and min values, I chose to focus on material type. I discovered the most common checkout material type being `most_common_checkout_material.R`, and the least common material type being `least_common_material.R`.


1. What is the average number of checkouts?

Answer: 122.8106



2. What month has the most checkouts?

Answer: May; 1644 checkouts



3. What year has the least amount of checkouts?

Answer: 2023; 151 checkouts



4. What is the most common checkout material type?

Answer: Audiobooks



5. What is the least common material type?

Answer: Books



These 5 questions allowed me to properly examine the data, allowing me to make new discoveries about checkout data regarding the novel, Normal People at the Seattle Public Library.

```{r, echo = TRUE, p1}

```

### The Dataset

#### Who collected/published the data?
The Seattle Public Library

#### What are the parameters of the data (dates, number of checkouts, kinds of books, etc.)?
The parameters within the dataset include Usage Class, Checkout Type, Material Type, Checkout Year, Checkout Month, number of checkouts, Title, ISBN, author, genre, Publisher, and Publication Year.

#### How was the data collected or generated?
The data was collected and generated by the Seattle Public Library database

#### Why was the data collected?
The data was collected to look at the checkout data at the Seattle Public Library, to allow open knowledge access to the public, this data allows people to visualize trends in data and various categories.

#### What, if any, ethical questions do you need to consider when working with this data?
The data collected from the Seattle Public Library between April 2019 and February 2023 is unbiased data, collected through checkout machines. However, it is important to consider possible ethical questions that may change data accuracy, some of which include: people taking books without proper checking out and machine malfunction. When working with this data to answer the questions at hand, it is important to weigh the accuracy of data. In this specific instance, it is most likely that the data is accurate.

#### What are possible limitations or problems with this data?   (at least 200 words)
The Normal People dataset from the Seattle Public Library represents a single library. As a result, the data does not accurately reflect checkout patterns across global libraries and data systems. For example, if the library serves a unique demographic or has a specific collection, the observed patterns will not represent all checkout patterns.

Another potential concern with the Normal People dataset is its limited scope - it only covers three years of data. This makes it challenging to analyze trends over time or compare the data to previous years. In my data science class last quarter, I learned that data is the most accurate with as much collected information as possible. As a result, the trends in the Normal People dataset will be most accurate as checkout data continues to be collected.

The Normal People dataset may also suffer from potential errors and inconsistencies in the data collection process. For example, there may be discrepancies in how checkout data has been recorded or there may be different methods used to count checkouts. These manual and technical issues could lead to inaccuracies in the dataset and may impact the validity of conclusions drawn from the data. As a result, it is important to carefully review the data and consider potential sources of error before drawing any definitive conclusions.

### First Trends Over Time Chart

I made a line chart that represents checkout data over time, because I was interested in seeing how different material types fluctuated in popularity since 2019.

The line chart titled “Total Checkouts by Year” displays the total number of checkouts by year over time using data from the Seattle Public Library. Since the book was published in 2019, the library dataset has less than 4 years of checkout data. As a result, there are less than 4 years worth of data featured within the chart. There is a noticeable peak in book checkout data in 2020 - this may possibly be a result from immediate positive feedback from the novel. Soon after in early January, the chart sees a large plunge from 600+ checkouts to ~60 checkouts within ~6 months. This sudden plunge in data may be representative from the COVID-19 pandemic and people being more cautious of hygiene. Between 2020 and 2021, Ebook popularity grows steadily, followed by all checkout data from Normal People to plunge and stagger between 0 and 100 checkouts per year between June 2021 and January 2023.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

# Load necessary libraries
library(dplyr)
library(ggplot2)

# Read in the data
normal_data <- read.csv("file:///Users/connorchan/Library/Messages/Attachments/dd/13/00961DEA-54E7-47C6-84E3-697CD2A044EA/Normal_People_A3_Checkouts_by_Title.csv")

# Clean up variable names
colnames(normal_data) <- c("Usage_Class", "Checkout_Type", "Material_Type", "Checkout_Year", "Checkout_Month", "Checkout_Number")

# Convert Checkout_Year and Checkout_Month to a single date variable
normal_data$Date <- as.Date(paste0(normal_data$Checkout_Year, "-", normal_data$Checkout_Month, "-01"))

# Filter for Books, Ebooks, and Audiobooks only
normal_data <- subset(normal_data, Material_Type %in% c("BOOK", "EBOOK", "AUDIOBOOK"))

# Group by Material_Type and Date, and summarize by summing Checkout_Number
normal_data <- aggregate(Checkout_Number ~ Material_Type + Date, data = normal_data, FUN = sum)

# Plot the data using ggplot2
ggplot(normal_data, aes(x = Date, y = Checkout_Number, color = Material_Type)) +
  geom_line() +
  labs(x = "Checkout Date", y = "Number of Checkouts", color = "Material Type", title = "Total Checkouts by Year - Normal People") +
  scale_x_date(date_labels = "%Y-%m", date_breaks = "1 year") +
  theme_minimal()

```

### Second Trends Over Time Chart

I decided to make a stacked bar chart to measure the number of checkouts over time in addition to material type.The chart helps to identify patterns in the checkout data over the years 2019 to early 2023.From the chart, we can see a shift in popularity of material types between 2019 and 2020. This is the same trend we visualized in our line first line chart. Additionally, there is a steady decrease in popularity of checkouts from the Seattle Public Library. This result may be from various reasons including COVID-19, a decreasing interest in the novel, technological issues, etc.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

# Load necessary libraries
library(dplyr)
library(ggplot2)

# Read in the data
normal_data <- read.csv("file:///Users/connorchan/Library/Messages/Attachments/dd/13/00961DEA-54E7-47C6-84E3-697CD2A044EA/Normal_People_A3_Checkouts_by_Title.csv")

# Clean up variable names
colnames(normal_data) <- c("Usage_Class", "Checkout_Type", "Material_Type", "Checkout_Year", "Checkout_Month", "Checkout_Number")

# Filter for Books, Ebooks, and Audiobooks only
normal_data <- subset(normal_data, Material_Type %in% c("BOOK", "EBOOK", "AUDIOBOOK"))

# Group by Material_Type and Checkout_Year, and summarize by summing Checkout_Number
normal_data <- aggregate(Checkout_Number ~ Material_Type + Checkout_Year, data = normal_data, FUN = sum)

# Plot the data using ggplot2
ggplot(normal_data, aes(x = Checkout_Year, y = Checkout_Number, fill = Material_Type)) +
  geom_bar(stat = "identity") +
  labs(x = "Checkout Year", y = "Number of Checkouts", fill = "Material Type", title = "Normal People Material Type Checkouts") +
  theme_minimal()

```

### My Choice

The chart displays a pie chart with the title "Material Type Breakdown of Checkouts (2019-2023). The pie chart shows the total checkouts for each material type, with each material type represented by a different colored slice of the pie. The pie chart allows use to see the full material type breakdown between 2019 and 2023. This chart evaluates which material types are most popular and less popular.

```{r, echo = FALSE, warning=FALSE, message=FALSE}

library(dplyr)
library(ggplot2)

# Load data
normal_data <- read.csv("file:///Users/connorchan/Library/Messages/Attachments/dd/13/00961DEA-54E7-47C6-84E3-697CD2A044EA/Normal_People_A3_Checkouts_by_Title.csv")

# Filter data for years 2019-2023 and calculate total checkouts by material type
material_counts <- normal_data %>%
  filter(CheckoutYear >= 2019 & CheckoutYear <= 2023) %>%
  group_by(MaterialType) %>%
  summarize(TotalCheckouts = sum(Checkouts))

# Create pie chart
ggplot(material_counts, aes(x = "", y = TotalCheckouts, fill = MaterialType)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  theme_void() +
  labs(title = "Normal People Material Type Breakdown of Checkouts (2019-2023)")

```